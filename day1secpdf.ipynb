{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-31T09:30:31.065178Z",
     "iopub.status.busy": "2025-03-31T09:30:31.06489Z",
     "iopub.status.idle": "2025-03-31T09:30:32.58451Z",
     "shell.execute_reply": "2025-03-31T09:30:32.583327Z",
     "shell.execute_reply.started": "2025-03-31T09:30:31.065153Z"
    },
    "id": "VWZlEwomGDir",
    "outputId": "e4e4a419-7be5-4b0e-c534-25a089c65600",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running locally\n",
      "len(GOOGLE_API_KEY)=39\n"
     ]
    }
   ],
   "source": [
    "# !pip install -Uq \"google-genai==1.9.0\"\n",
    "# !pip install -Uq \"duckdb==1.2.2\"\n",
    "# !pip install -Uq \"python-duckdb==1.2.2\"\n",
    "\n",
    "import duckdb\n",
    "import os\n",
    "import pandas as pd\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "from google.api_core import retry\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "companies = 'alphabet-ms-nvidia'\n",
    "\n",
    "if 'KAGGLE_KERNEL_RUN_TYPE' in os.environ:\n",
    "  print(\"Running on Kaggle\")\n",
    "  from kaggle_secrets import UserSecretsClient\n",
    "  user_secrets = UserSecretsClient() \n",
    "  GOOGLE_API_KEY = user_secrets.get_secret(\"GOOGLE_API_KEY\")\n",
    "  data_dir = f'/kaggle/input/{companies}/'\n",
    "else: \n",
    "  print(\"Running locally\")\n",
    "  from dotenv import load_dotenv\n",
    "  load_dotenv()\n",
    "  GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")\n",
    "  data_dir = f'../SEC/data/tables_{companies}/'\n",
    "  \n",
    "print(f\"{len(GOOGLE_API_KEY)=}\")\n",
    "\n",
    "client = genai.Client(api_key=GOOGLE_API_KEY)\n",
    "\n",
    "is_retriable = lambda e: (isinstance(e, genai.errors.APIError) and e.code in {429, 503})\n",
    "\n",
    "if not hasattr(genai.models.Models.generate_content, '__wrapped__'):\n",
    "  genai.models.Models.generate_content = retry.Retry(    \n",
    "      predicate=is_retriable)(genai.models.Models.generate_content)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALTER TABLE num ALTER COLUMN ddate TYPE DATE USING STRPTIME(CAST(ddate AS BIGINT)::VARCHAR, '%Y%m%d')::DATE;\n",
      "Loaded 'num.csv' into DuckDB view 'num'\n",
      "ALTER TABLE sub ALTER COLUMN changed TYPE DATE USING STRPTIME(CAST(changed AS BIGINT)::VARCHAR, '%Y%m%d')::DATE;\n",
      "ALTER TABLE sub ALTER COLUMN period TYPE DATE USING STRPTIME(CAST(period AS BIGINT)::VARCHAR, '%Y%m%d')::DATE;\n",
      "ALTER TABLE sub ALTER COLUMN filed TYPE DATE USING STRPTIME(CAST(filed AS BIGINT)::VARCHAR, '%Y%m%d')::DATE;\n",
      "ALTER TABLE sub ALTER COLUMN floatdate TYPE DATE USING STRPTIME(CAST(floatdate AS BIGINT)::VARCHAR, '%Y%m%d')::DATE;\n",
      "ALTER TABLE sub ADD PRIMARY KEY (adsh);\n",
      "Loaded 'sub.csv' into DuckDB view 'sub'\n",
      "ALTER TABLE cal ADD PRIMARY KEY (adsh, grp, arc);\n",
      "Loaded 'cal.csv' into DuckDB view 'cal'\n",
      "ALTER TABLE txt ALTER COLUMN ddate TYPE DATE USING STRPTIME(CAST(ddate AS BIGINT)::VARCHAR, '%Y%m%d')::DATE;\n",
      "Loaded 'txt.csv' into DuckDB view 'txt'\n",
      "ALTER TABLE pre ADD PRIMARY KEY (adsh, report, line);\n",
      "Loaded 'pre.csv' into DuckDB view 'pre'\n",
      "ALTER TABLE ren ADD PRIMARY KEY (adsh, report);\n",
      "Loaded 'ren.csv' into DuckDB view 'ren'\n",
      "ALTER TABLE tag ADD PRIMARY KEY (tag, version);\n",
      "Loaded 'tag.csv' into DuckDB view 'tag'\n",
      "ALTER TABLE dim ADD PRIMARY KEY (dimhash);\n",
      "Loaded 'dim.csv' into DuckDB view 'dim'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create an in-memory DuckDB connection with primary key and date column support\n",
    "\n",
    "# conn = duckdb.connect(database=':memory:', read_only=False)\n",
    "conn = duckdb.connect(database=f'../SEC/{companies}.duckdb')\n",
    "\n",
    "sec_pk = {'sub': 'adsh', 'tag': 'tag, version', 'ren': 'adsh, report', 'pre': 'adsh, report, line', 'cal': 'adsh, grp, arc', 'dim': 'dimhash'}\n",
    "sec_date_column =  {'sub': ['changed', 'period', 'filed', 'floatdate'], 'num': ['ddate'], 'txt': ['ddate']} \n",
    "\n",
    "\n",
    "# List all files in the specified directory\n",
    "all_files = os.listdir(data_dir)\n",
    "csv_files = [f for f in all_files if f.endswith('.csv')]\n",
    "# Iterate through the CSV files and load them into DuckDB tables\n",
    "for file_name in csv_files:\n",
    "    file_path = os.path.join(data_dir, file_name)\n",
    "    table_name = os.path.splitext(file_name)[0]  # Use the filename (without extension) as the table nam\n",
    "    try:\n",
    "        conn.execute(f\"\"\"CREATE TABLE IF NOT EXISTS {table_name} AS SELECT * FROM read_csv('{file_path}', AUTO_DETECT=TRUE);\"\"\")\n",
    "        if table_name in sec_date_column:\n",
    "            strptimes: str = \"\"\n",
    "            for col in sec_date_column[table_name]:\n",
    "                sql_alter = f\"ALTER TABLE {table_name} ALTER COLUMN {col} TYPE DATE USING STRPTIME(CAST({col} AS BIGINT)::VARCHAR, '%Y%m%d')::DATE;\"\n",
    "                print(sql_alter)\n",
    "                conn.execute(sql_alter)\n",
    "        if table_name in sec_pk:\n",
    "            # Add primary key constraint\n",
    "            sql_pk = f\"ALTER TABLE {table_name} ADD PRIMARY KEY ({sec_pk[table_name]});\"\n",
    "            print(sql_pk)\n",
    "            conn.execute(sql_pk)\n",
    "        print(f\"Loaded '{file_name}' into DuckDB view '{table_name}'\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading '{file_name}': {e}\")\n",
    "\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the database schema for context for the LLM\n",
    "\n",
    "tables = conn.execute(\"SELECT table_name FROM information_schema.tables WHERE table_schema = 'main'\").fetchall()\n",
    "schema_output = ['DuckDB Database Schema:']\n",
    "\n",
    "for (table_name,) in tables:\n",
    "    schema_output.append(f\"\\nTable Name: '{table_name}'\")\n",
    "    schema = conn.execute(f\"PRAGMA table_info('{table_name}')\").fetchall()\n",
    "    schema_output.append(\"Columns:\")\n",
    "    for column in schema:\n",
    "        cid, name, dtype, notnull, pk, default = column\n",
    "        schema_output.append(f\"  {name} {dtype}{\" NOTNULL,\" if notnull else \",\"}\")\n",
    "# conn.close()\n",
    "schema = \"\\n\".join(schema_output)\n",
    "print(f\"{len(schema)=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_tables() -> list[str]:\n",
    "    \"\"\"Retrieve the names of all tables in the database.\"\"\"\n",
    "    # Include print logging statements so you can see when functions are being called.\n",
    "    print(' - DB CALL: list_tables()')\n",
    "\n",
    "    tables_raw = conn.execute(\"SELECT table_name FROM information_schema.tables WHERE table_schema = 'main'\").fetchall()\n",
    "    tables = []\n",
    "    for (table_name,) in tables_raw:\n",
    "        tables.append(table_name)\n",
    "    return tables\n",
    "\n",
    "list_tables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def describe_table(table_name: str) -> list[tuple[str, str]]:\n",
    "    \"\"\"Look up the table schema.\n",
    "\n",
    "    Returns:\n",
    "      List of columns, where each entry is a tuple of (column, type).\n",
    "    \"\"\"\n",
    "    print(f' - DB CALL: describe_table({table_name})')\n",
    "\n",
    "    schema = conn.execute(f\"PRAGMA table_info('{table_name}')\").fetchall()\n",
    "    schema_output = []\n",
    "    for column in schema:\n",
    "        cid, name, dtype, notnull, pk, default = column\n",
    "        schema_output.append((name, dtype))\n",
    "    return schema_output\n",
    "\n",
    "describe_table(\"sub\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_item(company_name: str, item: str) -> list[tuple[str, str]]:\n",
    "    \"\"\"Look up the table schema.\n",
    "\n",
    "    Returns:\n",
    "      List of columns, where each entry is a tuple of (column, type).\n",
    "    \"\"\"\n",
    "    print(f' - DB CALL: get_item({company_name}, {item})')\n",
    "    results = conn.execute(f\"\"\"select date, name, items.* from statements inner join items on statements.statement_id  = items.statement_id where name like '{name}%' and duration = \"Twelve months ended\" and category = \"{item}\" order by date;\"\"\").fetchall()\n",
    "    return results\n",
    "\n",
    "get_item(\"Microsoft\", \"Operating Revenue\")\n",
    "# select date, company_name, items.* from statements inner join items on statements.statement_id  = items.statement_id where company_name like 'Barrick%' and duration = \"Twelve months ended\" and category = \"Operating Revenue\" order by date;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cik_name_dict = {1652044: 'ALPHABET INC.', 789019: 'MICROSOFT CORP', 1045810: 'NVIDIA CORP'}\n",
    "name_cik_dict = {'ALPHABET INC.': 1652044, 'MICROSOFT CORP': 789019, 'NVIDIA CORP': 1045810}\n",
    "\n",
    "def cik_to_name(cik: str) -> str:\n",
    "    name: str = cik_name_dict.get(int(cik), None)\n",
    "    if name:\n",
    "        return name\n",
    "    else:\n",
    "        return f\"Unknown CIK: {cik}\"\n",
    "    \n",
    "def name_to_cik(name: str) -> str:\n",
    "    cik: int = name_cik_dict.get(name, None)\n",
    "    if cik:\n",
    "        return str(cik)\n",
    "    else:\n",
    "        return f\"Unknown Name: {name}\"\n",
    "\n",
    "\n",
    "def execute_query(sql: str) -> list[list[str]]:\n",
    "    \"\"\"Execute an SQL statement, returning the results.\"\"\"\n",
    "    print(f' - DB CALL: execute_query({sql})')\n",
    "\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    cursor.execute(sql)\n",
    "    list_tuples = cursor.fetchall()\n",
    "    list_list_str = [list(map(str, row)) for row in list_tuples]\n",
    "    return list_list_str\n",
    "\n",
    "\n",
    "execute_query(\"select * from pre limit 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_instructions = \"\"\"SUB – Submission table; this includes one record for each XBRL submission. The table includes fields\n",
    "of information pertinent to the submission and the filing entity. Information is extracted from the Commission's EDGAR system and the filings submitted to the CCommission by registrants.\n",
    "TAG – Tag table; includes defining information about each tag. Information includes tag descriptions (documentation labels), taxonomy version information and other tag attributes.\n",
    "DIM – Dimension table; used to provide more detail in numeric and non-numeric facts.\n",
    "NUM – Number table; this includes one row for each distinct amount from each submission included in the SUB table. The Number table includes, for every submission, all line item values\n",
    "as rendered by the C ommission Viewer/Previewer.\n",
    "TXT – Text table; this is the plain text of all the non-numeric tagged items in the submission.\n",
    "REN – Rendering table; this contains data from the rendering of the filing on the Commission\n",
    "website.\n",
    "PRE – Presentation table; this provides information about how the tags and numbers were presented in the primary financial statements.\n",
    "CAL – Calculation table; provides information to arithmetically relate tags in a filing.\n",
    "\n",
    "\n",
    "Organization\n",
    "Note that this table represents quarterly and annual uncorrected and \"as filed\" EDGAR document submissions containing multiple reporting periods (including amendments of prior submissions). Data in this\n",
    "submitted form may contain redundancies, inconsistencies, and discrepancies relative to other publication formats. There are eight tables. Each quarterly table is accompanied by a metadata file conforming to\n",
    "the W3C specification for tabular data (https://www.w3.org/TR/2015/REC -tabular-data-model-20151217/ ) that encodes the following information about the tables and their relationships to each other.\n",
    "1. SUB identifies all the EDGAR submissions in the table, with each row having the unique (primary) key adsh, a 20 character EDGAR Accession Number with dashes in positions 11 and 14.\n",
    "2. TAG is a table of all tags used in the submissions, both standard and custom. These fields\n",
    "comprise a unique compound key:\n",
    "1) tag – tag used by the filer\n",
    "2) version – if a standard tag, the taxonomy of origin, otherwise equal to adsh.3. DIM is a table containing XBRL dimensional tags. The unique key of each row is a 16-byte\n",
    "hexadecimal value:\n",
    "1) dimh - 0 representing no XBRL dimensions, otherwise the MD5 hash of the dimension tags.\n",
    "(The MD5 algorithm is a widely used hash function producing a 128-bit hash value,\n",
    "conventionally shown in human readable form as a 32-byte string.)\n",
    "4. NUM is a table of all numeric XBRL facts presented on the primary financial statements. These\n",
    "fields comprise a unique compound key:\n",
    "1) adsh - EDGAR accession number\n",
    "2) tag - tag used by the filer\n",
    "3) version – if a standard tag, the taxonomy of origin, otherwise equal to adsh.\n",
    "4) ddate - period end date\n",
    "5) qtrs - duration in number of quarters\n",
    "6) uom - unit of measure\n",
    "7) dimh - 16-byte dimensional qualifier\n",
    "8) iprx - a sequential integer used to distinguish otherwise identical facts\n",
    "5. TXT is a table that contains the plain (no HTML) text of each non-numeric XBRL fact. These fields\n",
    "comprise a unique compound key:\n",
    "1) adsh - EDGAR accession number\n",
    "2) tag – tag used by the filer\n",
    "3) version – if a standard tag, the taxonomy of origin, otherwise equal to adsh\n",
    "4) ddate - period end date\n",
    "5) qtrs - duration in number of quarters\n",
    "6) dimh - dimension hash value\n",
    "7) iprx - a sequential integer used to distinguish otherwise identical facts\n",
    "6. REN is a table providing a summary of the filing as it would be rendered on the C ommission\n",
    "website. These fields comprise a unique compound key:\n",
    "1) adsh - EDGAR accession number\n",
    "2) report - position in sequential display order\n",
    "7. PRE is a table that provides the text assigned by the filer to each line item in the primary financial\n",
    "statements, the order in which the line item appeared, and the tag assigned to it. These fields\n",
    "comprise a unique compound key:\n",
    "1) adsh – EDGAR accession number\n",
    "2) report – sequential number of report within the submission\n",
    "3) line – sequential number of line within a report.\n",
    "8. CAL is a table that provides arithmetic relationships among the tags in a filing. These fields\n",
    "comprise a unique compound key:\n",
    "1) adsh - EDGAR accession number\n",
    "2) grp - sequential number of a group of relationships within the submission\n",
    "3) arc - sequential number of relationship within the group of relationships\n",
    "\n",
    "The relationship of the tables is as shown in Figure 1. The Accession Number (adsh) found in the NUM table can be used to retrieve information about the submission in SUB. Each row of data in NUM or TXT was tagged by the filer using a tag. Information about the tag used can be found in TAG. Each row of data in NUM or TXT appears on one or more lines of reports detailed in PRE.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are the Python functions defined above.\n",
    "db_tools = [list_tables, describe_table, execute_query]\n",
    "\n",
    "\n",
    "instruction =\"\"\"\\n\\nYou are a helpful chatbot that can interact with a DuckDB SQL database. \n",
    "You will take the users questions and turn them into SQL queries using the tools available. \n",
    "Once you have the information you need, you will answer the user's question using the data returned.\n",
    "\n",
    "Use execute_query to issue an SQL SELECT query.\"\"\"\n",
    "\n",
    "instruction2 = \"\"\"You are a helpful chatbot that can interact with only a DuckDB SQL database with the following schema:\n",
    " \\n{schema}. \\n\n",
    "You will take the users questions and turn them into SQL queries using the tools available. \n",
    "Once you have the information you need, you will answer the user's question using the data returned.\n",
    "\"\"\"\n",
    "\n",
    "# Start a chat with automatic function calling enabled.\n",
    "chat = client.chats.create(\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    config=types.GenerateContentConfig(\n",
    "        system_instruction=instruction2,\n",
    "        tools=db_tools,\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = chat.send_message(\"List the available tables?\")\n",
    "print(f\"\\n{resp.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = chat.send_message(\" Which table contains company names and CIKs? What is the name of the company with CIK 1652044?\")\n",
    "print(f\"\\n{resp.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = chat.send_message(\"Return the rows in the sub table for 'MICROSOFT CORP'\")\n",
    "print(f\"\\n{resp.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-31T09:30:35.570603Z",
     "iopub.status.busy": "2025-03-31T09:30:35.570251Z",
     "iopub.status.idle": "2025-03-31T09:30:48.493915Z",
     "shell.execute_reply": "2025-03-31T09:30:48.49302Z",
     "shell.execute_reply.started": "2025-03-31T09:30:35.570572Z"
    },
    "id": "Jxx92-z90tPS",
    "outputId": "1ed16b55-d456-4099-acac-04e9540c6aee",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "document_file = client.files.upload(file='fsnds.pdf')\n",
    "request = 'How is the sub table connected to the cal table?'\n",
    "\n",
    "def summarise_doc(request: str) -> str:\n",
    "  \"\"\"Execute the request on the uploaded document.\"\"\"\n",
    "  # Set the temperature low to stabilise the output.\n",
    "  config = types.GenerateContentConfig(temperature=0.0)\n",
    "  response = client.models.generate_content(\n",
    "      model='gemini-2.0-flash',\n",
    "      config=config,\n",
    "      contents=[request, document_file],\n",
    "  )\n",
    "\n",
    "  return response.text\n",
    "\n",
    "summary = summarise_doc(request)\n",
    "Markdown(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-31T09:30:48.495065Z",
     "iopub.status.busy": "2025-03-31T09:30:48.494779Z",
     "iopub.status.idle": "2025-03-31T09:30:49.938861Z",
     "shell.execute_reply": "2025-03-31T09:30:49.937607Z",
     "shell.execute_reply.started": "2025-03-31T09:30:48.495042Z"
    },
    "id": "xEAXtJte-Ajv",
    "outputId": "04459189-13ee-49e6-fe4d-525d323b1609",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "document_file = client.files.upload(file='fsnds.pdf')\n",
    "request = 'Which table(s) have a cik column?'\n",
    "\n",
    "def summarise_doc(request: str) -> str:\n",
    "  \"\"\"Execute the request on the uploaded document.\"\"\"\n",
    "  # Set the temperature low to stabilise the output.\n",
    "  config = types.GenerateContentConfig(temperature=0.0)\n",
    "  response = client.models.generate_content(\n",
    "      model='gemini-2.0-flash',\n",
    "      config=config,\n",
    "      contents=[request, schema_output],\n",
    "  )\n",
    "\n",
    "  return response.text\n",
    "\n",
    "summary = summarise_doc(request)\n",
    "Markdown(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qfkQ0lUByy2o"
   },
   "source": [
    "In this example, the model generated a textual justification that was set up in a chat context. This full text response is useful both for human interpretation and for giving the model a place to \"collect notes\" while it assesses the text and produces a final score. This \"note taking\" or \"thinking\" strategy typically works well with auto-regressive models, where the generated text is passed back into the model at each generation step. This means the working \"notes\" are used when generating final result output.\n",
    "\n",
    "In the next turn, the model converts the text output into a structured response. If you want to aggregate scores or use them programatically then you want to avoid parsing the unstructured text output. Here the `SummaryRating` schema is passed, so the model converts the chat history into an instance of the `SummaryRating` enum."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 30918,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "ggenai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
